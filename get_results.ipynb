{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVALwvXkozSI"
   },
   "source": [
    "# Article..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFiQS-lToy65"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y4_xXNSanX6V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'qaoa'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
      "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
      "remote: Total 69 (delta 27), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (69/69), 147.95 KiB | 2.11 MiB/s, done.\n",
      "Resolving deltas: 100% (27/27), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NesyaLab/qaoa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LybW0n0dnimP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/main/Desktop/qaoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "679axBjquUmQ"
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2Fdoh0_Upj1E"
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ztMHfEvkoJkp"
   },
   "outputs": [],
   "source": [
    "from classes import Problems as P\n",
    "from classes import Qaoa as Q\n",
    "from functions import qaoa_utilities as qaoa_utils\n",
    "from functions import maxcut_utilities as mcut_utils\n",
    "from functions import qaoa_optimizers as optims\n",
    "from functions import symmetry_utilities as sym_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yZyXaAF7oSce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3dhN7_1ownB"
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d4v9wrBAonNk"
   },
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i in range(num_graphs):\n",
    "    graph_path =  \"/graph_\"+str(i)+\".nx\"\n",
    "    with open(\"data/graph_\"+str(i)+\".nx\", 'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YIPPApbrfva"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bz2Ftqy1qXjN"
   },
   "outputs": [],
   "source": [
    "!mkdir results\n",
    "results_path = \"/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9spvD0Rrq1i"
   },
   "source": [
    "### Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tiTJVIctrsnj"
   },
   "outputs": [],
   "source": [
    "bfs = [0]*len(graphs)\n",
    "idx = 0\n",
    "for graph in graphs:\n",
    "    bfs[idx] = mcut_utils.compute_max_cut_exactly(graph)\n",
    "    idx += 1\n",
    "\n",
    "with open(\"results/brute_force_solution\", 'wb') as file:\n",
    "    pickle.dump(bfs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDUtRYA7p06o"
   },
   "source": [
    "### Qaoa vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Dr3Ixrv8pqJ9"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_vanilla_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            qaoa = Q.Qaoa(p=layer, G=G, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rmx4VoYqy_-"
   },
   "source": [
    "### QAOA extended with one \"shadow\" node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HqIGABtjqyIP"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_1_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4O1t3Tkq7L2"
   },
   "source": [
    "### QAOA extended with two \"shadow\" nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RuSvnpAIqyAi"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_2_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            G_.add_node(N+1)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii7pYflarCR2"
   },
   "source": [
    "### QAOA extended with one pendent edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "547v59T-pueu"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_3_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            u = list(G_.nodes())[N]\n",
    "            v = list(G_.nodes())[random.randint(0,N-1)]\n",
    "            G_.add_edge(u,v)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, _ = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            qaoa = Q.Qaoa(p=layer, G=graphs[idx], betas=x[:layer], gammas=x[layer:], mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            _, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u_a_zJsrGrO"
   },
   "source": [
    "### QAOA reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2uML-9dNrCtG"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_reduced_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_prime = P.Problems(p_type=\"custom\", G=G_)\n",
    "        opt = [0]\n",
    "        for edge in G_prime.get_edges():\n",
    "            G_reduced = G_prime.get_graph().copy()\n",
    "            G_reduced.remove_edges_from([edge])\n",
    "            reduced_graph_instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "            qaoa = Q.Qaoa(p=layer, G=G, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            opt.append(AR)\n",
    "        with open(\"results/\" + name, 'wb') as file:\n",
    "            pickle.dump((x,f,max(opt)), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytZsqF_ksDpx"
   },
   "source": [
    "### Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XY8PcqccsE9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/b9jm0kpj3k51rtzysg66fpnr0000gn/T/ipykernel_68923/3833129541.py:9: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  rho = float(max(graph.get_adjacency_spectrum()))\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING SPECTRAL RADIUS METRIC FOR EACH GRAPH\n",
    "\n",
    "idx = 0\n",
    "metric = {}\n",
    "spectral_radii = []\n",
    "avg_degrees = []\n",
    "for graph in graphs:\n",
    "    # The max eigenvalue is real\n",
    "    rho = float(max(graph.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(graph.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii.append(rho)\n",
    "    avg_degrees.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric[idx] = [avg_degrees[idx] / spectral_radii[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii, file)\n",
    "with open(\"results/spectral_metric_unperturbed\", 'wb') as file:\n",
    "    pickle.dump(metric, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KYSw3LcesLdG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/b9jm0kpj3k51rtzysg66fpnr0000gn/T/ipykernel_68923/3912479800.py:13: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  rho = float(max(instance.get_adjacency_spectrum()))\n",
      "/var/folders/fn/b9jm0kpj3k51rtzysg66fpnr0000gn/T/ipykernel_68923/3912479800.py:35: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  rho = float(max(instance.get_adjacency_spectrum()))\n",
      "/var/folders/fn/b9jm0kpj3k51rtzysg66fpnr0000gn/T/ipykernel_68923/3912479800.py:60: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  rho = float(max(instance.get_adjacency_spectrum()))\n",
      "/var/folders/fn/b9jm0kpj3k51rtzysg66fpnr0000gn/T/ipykernel_68923/3912479800.py:87: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  rho = float(max(instance.get_adjacency_spectrum()))\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING SPECTRAL RADIUS METRIC FOR EACH GRAPH PERTURBATION\n",
    "\n",
    "# One shadow node\n",
    "idx = 0\n",
    "metric_shadow1 = {}\n",
    "spectral_radii_shadow1 = []\n",
    "avg_degrees_shadow1 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_shadow1.append(rho)\n",
    "    avg_degrees_shadow1.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_shadow1[idx] = [avg_degrees_shadow1[idx] / spectral_radii_shadow1[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_shadow1\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_shadow1, file)\n",
    "with open(\"results/spectral_metric_shadow1\", 'wb') as file:\n",
    "    pickle.dump(metric_shadow1, file)\n",
    "\n",
    "# Two shadow nodes\n",
    "idx = 0\n",
    "metric_shadow2 = {}\n",
    "spectral_radii_shadow2 = []\n",
    "avg_degrees_shadow2 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    G.add_node(N+1)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_shadow2.append(rho)\n",
    "    avg_degrees_shadow2.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_shadow2[idx] = [avg_degrees_shadow2[idx] / spectral_radii_shadow2[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_shadow2\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_shadow2, file)\n",
    "with open(\"results/spectral_metric_shadow2\", 'wb') as file:\n",
    "    pickle.dump(metric_shadow2, file)\n",
    "\n",
    "\n",
    "# One pendent edge\n",
    "idx = 0\n",
    "metric_pendent = {}\n",
    "spectral_radii_pendent = []\n",
    "avg_degrees_pendent = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    u = list(G.nodes())[N]\n",
    "    v = list(G.nodes())[random.randint(0,N-2)]\n",
    "    G.add_edge(u,v)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_pendent.append(rho)\n",
    "    avg_degrees_pendent.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_pendent[idx] = [avg_degrees_pendent[idx] / spectral_radii_pendent[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_pendent\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_pendent, file)\n",
    "with open(\"results/spectral_metric_pendent\", 'wb') as file:\n",
    "    pickle.dump(metric_pendent, file)\n",
    "\n",
    "# One deleted edge\n",
    "idx = 0\n",
    "metric_deleted = {}\n",
    "spectral_radii_deleted = {}\n",
    "avg_degrees_deleted = {}\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G_ = P.Problems(p_type=\"custom\", G=G)\n",
    "    metric_deleted_vec = []\n",
    "    avg_degrees_deleted_vec = []\n",
    "    spectral_radii_deleted_vec = []\n",
    "    for edge in G_.get_edges():\n",
    "        G_reduced = G_.get_graph().copy()\n",
    "        G_reduced.remove_edges_from([edge])\n",
    "        instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "        rho = float(max(instance.get_adjacency_spectrum()))\n",
    "        D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "        spectral_radii_deleted_vec.append(rho)\n",
    "        avg_degrees_deleted_vec.append(int(np.sum(D)/D.shape[0]))\n",
    "    spectral_radii_deleted[idx] = max(spectral_radii_deleted_vec)\n",
    "    avg_degrees_deleted[idx] = max(avg_degrees_deleted_vec)\n",
    "    metric_deleted[idx] = [avg_degrees_deleted[idx] / spectral_radii_deleted[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_deleted\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_deleted, file)\n",
    "with open(\"results/spectral_metric_deleted\", 'wb') as file:\n",
    "    pickle.dump(metric_deleted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xvURQT9BsPUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1.0000000000000002], 1: [1.0000000000000002], 2: [1.0000000000000004], 3: [1.0000000000000002], 4: [0.7071067811865475], 5: [0.7151956979711059], 6: [0.6549730996262775], 7: [0.8529673390049615], 8: [0.618033988749895], 9: [0.5257311121191344], 10: [0.48969702869403314], 11: [0.46417900254028893], 12: [1.0000000000000002], 13: [1.0000000000000002], 14: [1.0], 15: [1.000000000000001]} \n",
      "\n",
      "{0: [0.6666666666666667], 1: [0.8000000000000002], 2: [0.8571428571428575], 3: [0.8888888888888891], 4: [0.0], 5: [0.7151956979711059], 6: [0.6549730996262775], 7: [0.8529673390049615], 8: [0.618033988749895], 9: [0.5257311121191344], 10: [0.48969702869403314], 11: [0.46417900254028893], 12: [0.6666666666666667], 13: [0.6666666666666669], 14: [0.6666666666666666], 15: [0.6666666666666674]} \n",
      "\n",
      "{0: [0.6666666666666667], 1: [0.6000000000000001], 2: [0.7142857142857146], 3: [0.7777777777777779], 4: [0.0], 5: [0.7151956979711059], 6: [0.32748654981313874], 7: [0.6397255042537211], 8: [0.618033988749895], 9: [0.5257311121191344], 10: [0.48969702869403314], 11: [0.46417900254028893], 12: [0.6666666666666667], 13: [0.6666666666666669], 14: [0.6666666666666666], 15: [0.6666666666666674]} \n",
      "\n",
      "{0: [0.6480607984465379], 1: [0.7945901385941809], 2: [0.8549331679346296], 3: [0.8877831927720411], 4: [0.6180339887498946], 5: [0.7041726696910162], 6: [0.6403164731387913], 7: [0.847658828893256], 8: [0.5411961001461972], 9: [0.4759631494779682], 10: [0.4612838521621938], 11: [0.4609917029445009], 12: [0.6480607984465379], 13: [0.6537132010871827], 14: [0.6566954302006853], 15: [0.6585341472686127]} \n",
      "\n",
      "{0: [0.7807764064044148], 1: [0.850781059358212], 2: [0.8860009363293818], 3: [0.9075364531836616], 4: [0.0], 5: [0.7695053061036752], 6: [0.6634983179151014], 7: [0.8620113551190869], 8: [0.7071067811865475], 9: [0.5411961001461972], 10: [0.5000000000000004], 11: [0.4718837988396799], 12: [0.7807764064044148], 13: [0.7296388847850819], 14: [0.7083430787040089], 15: [0.6991037150684638]}\n"
     ]
    }
   ],
   "source": [
    "# CHECK\n",
    "\n",
    "print(metric, \"\\n\")\n",
    "print(metric_shadow1, \"\\n\")\n",
    "print(metric_shadow2, \"\\n\")\n",
    "print(metric_pendent, \"\\n\")\n",
    "print(metric_deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poCyqtNssbgJ"
   },
   "source": [
    "### Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AUolVxrpscWk"
   },
   "outputs": [],
   "source": [
    "# CALCULATING |AUT(G)| FOR EACH GRAPH\n",
    "\n",
    "num_symmetries = []\n",
    "generating_symmetries = []\n",
    "for graph in graphs:\n",
    "    adjacency_dict = graph.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=graph, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=graph, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries.append(num_automorphisms)\n",
    "    generating_symmetries.append(generators)\n",
    "with open(\"results/aut_G\", 'wb') as file:\n",
    "      pickle.dump((num_symmetries,generating_symmetries), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aUXQ0ZylsdvN"
   },
   "outputs": [],
   "source": [
    "# CALCULATING |AUT(G')| FOR EACH GRAPH PERTURBATION\n",
    "\n",
    "# One shadow node\n",
    "num_symmetries_shadow1 = []\n",
    "generating_symmetries_shadow1 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_shadow1.append(num_automorphisms)\n",
    "    generating_symmetries_shadow1.append(generators)\n",
    "\n",
    "\n",
    "# Two shadow nodes\n",
    "num_symmetries_shadow2 = []\n",
    "generating_symmetries_shadow2 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    G.add_node(N+1)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_shadow2.append(num_automorphisms)\n",
    "    generating_symmetries_shadow2.append(generators)\n",
    "\n",
    "\n",
    "# One pendent edge\n",
    "num_symmetries_pendent = []\n",
    "generating_symmetries_pendent = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    u = list(G.nodes())[N]\n",
    "    v = list(G.nodes())[random.randint(0,N-2)]\n",
    "    G.add_edge(u,v)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_pendent.append(num_automorphisms)\n",
    "    generating_symmetries_pendent.append(generators)\n",
    "\n",
    "\n",
    "# One deleted edge\n",
    "idx = 0\n",
    "num_symmetries_deleted = {}\n",
    "generating_symmetries_deleted= {}\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G_ = P.Problems(p_type=\"custom\", G=G)\n",
    "    num_symmetries_deleted_vec = []\n",
    "    generating_symmetries_deleted_vec = []\n",
    "    for edge in G_.get_edges():\n",
    "        G_reduced = G_.get_graph().copy()\n",
    "        G_reduced.remove_edges_from([edge])\n",
    "        instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "        adjacency_dict = instance.get_adjacency_dict()\n",
    "        num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "        generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "        num_symmetries_deleted_vec.append(num_automorphisms)\n",
    "        generating_symmetries_deleted_vec.append(generators)\n",
    "    num_symmetries_deleted[idx] = num_symmetries_deleted_vec\n",
    "    generating_symmetries_deleted[idx] = generating_symmetries_deleted_vec\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Si4PbhDysgZe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 720, 40320, 3628800, 2, 2, 1, 1, 2, 2, 2, 4, 24, 12, 12, 20]\n",
      "[24, 720, 40320, 3628800, 4, 2, 2, 1, 2, 2, 2, 4, 24, 12, 12, 20]\n",
      "[48, 1440, 80640, 7257600, 12, 4, 6, 2, 4, 4, 4, 8, 48, 24, 24, 40]\n",
      "[6, 120, 5040, 362880, 4, 1, 1, 1, 2, 2, 2, 2, 6, 2, 4, 2]\n",
      "{0: [4, 4, 4, 4, 4, 4], 1: [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48], 2: [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440], 3: [80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640, 80640], 4: [4, 4], 5: [4, 1, 1, 4, 6, 1, 1, 4], 6: [2, 2, 2, 1, 2, 2, 1, 1, 4], 7: [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1], 8: [8, 2, 2], 9: [8, 12, 2, 2, 2], 10: [12, 4, 4, 2, 1, 1, 8], 11: [12, 4, 4, 16, 2, 2, 4, 4, 4], 12: [4, 4, 4, 4, 4, 4], 13: [2, 4, 2, 2, 4, 4, 2, 2, 2], 14: [2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4], 15: [2, 2, 4, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2]}\n"
     ]
    }
   ],
   "source": [
    "# CHECK\n",
    "\n",
    "print(num_symmetries)\n",
    "print(num_symmetries_shadow1)\n",
    "print(num_symmetries_shadow2)\n",
    "print(num_symmetries_pendent)\n",
    "print(num_symmetries_deleted)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
